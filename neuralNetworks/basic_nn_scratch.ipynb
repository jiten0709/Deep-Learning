{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# building basic neural network from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "def mean_squared_error(ytrue, ypred):\n",
    "    return np.mean((ytrue - ypred) ** 2)\n",
    "\n",
    "class BasicNeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        self.weights_input_hidden = np.random.rand(input_size, hidden_size)\n",
    "        self.weights_hidden_output = np.random.rand(hidden_size, output_size)\n",
    "        self.bias_hidden = np.random.rand(1, hidden_size)\n",
    "        self.bias_output = np.random.rand(1, output_size)\n",
    "\n",
    "    # forward pass\n",
    "    def forward(self, x):\n",
    "        self.hidden_input = np.dot(x, self.weights_input_hidden) + self.bias_hidden\n",
    "        self.hidden_output = sigmoid(self.hidden_input)\n",
    "        self.output_input = np.dot(self.hidden_output, self.weights_hidden_output) + self.bias_output\n",
    "        self.output = sigmoid(self.output_input)\n",
    "\n",
    "        return self.output\n",
    "    \n",
    "    # backward pass\n",
    "    def backward(self, x, y, output, learning_rate):\n",
    "        output_error = y - output\n",
    "        output_delta = output_error * sigmoid_derivative(output)\n",
    "        hidden_error = output_delta.dot(self.weights_hidden_output.T)\n",
    "        hidden_delta = hidden_error * sigmoid_derivative(self.hidden_output)\n",
    "\n",
    "        self.weights_hidden_output += np.dot(self.hidden_output.T, output_delta) * learning_rate\n",
    "        self.bias_output += np.sum(output_delta, axis=0, keepdims=True) * learning_rate\n",
    "        self.weights_input_hidden += np.dot(x.T, hidden_delta) * learning_rate\n",
    "        self.bias_hidden += np.sum(hidden_delta, axis=0, keepdims=True) * learning_rate\n",
    "\n",
    "    # train the model\n",
    "    def train(self, x, y, epochs, learning_rate):\n",
    "        for epoch in range(epochs):\n",
    "            output = self.forward(x)\n",
    "            self.backward(x, y, output, learning_rate)\n",
    "            if epoch % 100 == 0:\n",
    "                print(f'Epoch {epoch}, Loss: {mean_squared_error(y, output)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.35606955903668114\n",
      "Epoch 100, Loss: 0.24992632072605808\n",
      "Epoch 200, Loss: 0.24985668597160893\n",
      "Epoch 300, Loss: 0.24979202555794666\n",
      "Epoch 400, Loss: 0.24972153304416167\n",
      "Epoch 500, Loss: 0.24964296454212415\n",
      "Epoch 600, Loss: 0.24955376832331322\n",
      "Epoch 700, Loss: 0.24945096712049358\n",
      "Epoch 800, Loss: 0.24933102096715065\n",
      "Epoch 900, Loss: 0.24918966289173522\n",
      "Epoch 1000, Loss: 0.24902169893281031\n",
      "Epoch 1100, Loss: 0.2488207625359602\n",
      "Epoch 1200, Loss: 0.2485790116063753\n",
      "Epoch 1300, Loss: 0.24828675429389918\n",
      "Epoch 1400, Loss: 0.2479319869794125\n",
      "Epoch 1500, Loss: 0.24749982510040106\n",
      "Epoch 1600, Loss: 0.24697180521966683\n",
      "Epoch 1700, Loss: 0.2463250376028425\n",
      "Epoch 1800, Loss: 0.2455311988490228\n",
      "Epoch 1900, Loss: 0.24455538776057562\n",
      "Epoch 2000, Loss: 0.2433549516564448\n",
      "Epoch 2100, Loss: 0.24187856926981627\n",
      "Epoch 2200, Loss: 0.24006620548245883\n",
      "Epoch 2300, Loss: 0.23785105350947489\n",
      "Epoch 2400, Loss: 0.23516511006101937\n",
      "Epoch 2500, Loss: 0.23195006020289255\n",
      "Epoch 2600, Loss: 0.22817366749736112\n",
      "Epoch 2700, Loss: 0.22384807590435424\n",
      "Epoch 2800, Loss: 0.21904171894563607\n",
      "Epoch 2900, Loss: 0.21387557525062562\n",
      "Epoch 3000, Loss: 0.2085011812736096\n",
      "Epoch 3100, Loss: 0.20306836259553906\n",
      "Epoch 3200, Loss: 0.19769581163287903\n",
      "Epoch 3300, Loss: 0.19245358716684013\n",
      "Epoch 3400, Loss: 0.187358360775146\n",
      "Epoch 3500, Loss: 0.1823761551025192\n",
      "Epoch 3600, Loss: 0.177425243767608\n",
      "Epoch 3700, Loss: 0.1723722325435821\n",
      "Epoch 3800, Loss: 0.1670159957589148\n",
      "Epoch 3900, Loss: 0.16106014381351708\n",
      "Epoch 4000, Loss: 0.15409605873203663\n",
      "Epoch 4100, Loss: 0.14566535936486827\n",
      "Epoch 4200, Loss: 0.1354798385860595\n",
      "Epoch 4300, Loss: 0.12367764961504066\n",
      "Epoch 4400, Loss: 0.1108077275021482\n",
      "Epoch 4500, Loss: 0.09760150457485184\n",
      "Epoch 4600, Loss: 0.08480297198737709\n",
      "Epoch 4700, Loss: 0.07303309303217703\n",
      "Epoch 4800, Loss: 0.06267215430321203\n",
      "Epoch 4900, Loss: 0.05383828706717246\n",
      "Epoch 5000, Loss: 0.04645634693061\n",
      "Epoch 5100, Loss: 0.040350530467267595\n",
      "Epoch 5200, Loss: 0.03531526525990039\n",
      "Epoch 5300, Loss: 0.03115498831180678\n",
      "Epoch 5400, Loss: 0.02770071941803282\n",
      "Epoch 5500, Loss: 0.024813570802254825\n",
      "Epoch 5600, Loss: 0.022382327675357055\n",
      "Epoch 5700, Loss: 0.0203190376964056\n",
      "Epoch 5800, Loss: 0.01855444785603022\n",
      "Epoch 5900, Loss: 0.01703399886434608\n",
      "Epoch 6000, Loss: 0.015714555798995257\n",
      "Epoch 6100, Loss: 0.01456183500861738\n",
      "Epoch 6200, Loss: 0.013548415805793804\n",
      "Epoch 6300, Loss: 0.012652216823298666\n",
      "Epoch 6400, Loss: 0.01185533130630936\n",
      "Epoch 6500, Loss: 0.011143135762360888\n",
      "Epoch 6600, Loss: 0.010503605503692393\n",
      "Epoch 6700, Loss: 0.009926786554460297\n",
      "Epoch 6800, Loss: 0.009404385919154394\n",
      "Epoch 6900, Loss: 0.008929451753280797\n",
      "Epoch 7000, Loss: 0.008496122135908944\n",
      "Epoch 7100, Loss: 0.008099426470699429\n",
      "Epoch 7200, Loss: 0.007735127494754853\n",
      "Epoch 7300, Loss: 0.0073995948083373335\n",
      "Epoch 7400, Loss: 0.007089703020808634\n",
      "Epoch 7500, Loss: 0.006802749237330539\n",
      "Epoch 7600, Loss: 0.006536385832505862\n",
      "Epoch 7700, Loss: 0.006288565377756627\n",
      "Epoch 7800, Loss: 0.006057495286687588\n",
      "Epoch 7900, Loss: 0.0058416002739778376\n",
      "Epoch 8000, Loss: 0.00563949113031861\n",
      "Epoch 8100, Loss: 0.0054499386294079525\n",
      "Epoch 8200, Loss: 0.005271851625831235\n",
      "Epoch 8300, Loss: 0.005104258591760216\n",
      "Epoch 8400, Loss: 0.004946291988463666\n",
      "Epoch 8500, Loss: 0.004797174985152425\n",
      "Epoch 8600, Loss: 0.0046562101298634135\n",
      "Epoch 8700, Loss: 0.004522769650367945\n",
      "Epoch 8800, Loss: 0.00439628712162466\n",
      "Epoch 8900, Loss: 0.004276250283272149\n",
      "Epoch 9000, Loss: 0.004162194828523013\n",
      "Epoch 9100, Loss: 0.00405369901647865\n",
      "Epoch 9200, Loss: 0.00395037898481117\n",
      "Epoch 9300, Loss: 0.0038518846601068007\n",
      "Epoch 9400, Loss: 0.003757896179844201\n",
      "Epoch 9500, Loss: 0.003668120753700981\n",
      "Epoch 9600, Loss: 0.003582289903213203\n",
      "Epoch 9700, Loss: 0.003500157028201482\n",
      "Epoch 9800, Loss: 0.003421495256185476\n",
      "Epoch 9900, Loss: 0.003346095537523569\n",
      "\n",
      "test the trained neural network:\n",
      "Input: [0 0] \n",
      "predicted output: [[0.05952516]\n",
      " [0.05952516]] \n",
      "round-off output: [[0]\n",
      " [0]] \n",
      "Actual output: [0]\n",
      "---------------------------\n",
      "Input: [0 1] \n",
      "predicted output: [[0.05952516]\n",
      " [0.05952516]] \n",
      "round-off output: [[0]\n",
      " [0]] \n",
      "Actual output: [1]\n",
      "---------------------------\n",
      "Input: [1 0] \n",
      "predicted output: [[0.94497837]\n",
      " [0.94519341]] \n",
      "round-off output: [[1]\n",
      " [1]] \n",
      "Actual output: [1]\n",
      "---------------------------\n",
      "Input: [1 1] \n",
      "predicted output: [[0.94497837]\n",
      " [0.94519341]] \n",
      "round-off output: [[1]\n",
      " [1]] \n",
      "Actual output: [0]\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "# xor dataset\n",
    "\n",
    "x = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y = np.array([[0], [1], [1], [0]])\n",
    "\n",
    "nn = BasicNeuralNetwork(2, 2, 1)\n",
    "nn.train(x, y, 10000, 0.1)\n",
    "\n",
    "print(\"\\ntest the trained neural network:\")\n",
    "for i in range(len(x)):\n",
    "    output_value = nn.forward(x[i][0])\n",
    "    round_output = np.where(output_value < 0.5, 0, 1)\n",
    "    print(f'Input: {x[i]} \\npredicted output: {output_value} \\nround-off output: {round_output} \\nActual output: {y[i]}')\n",
    "    print('---------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
